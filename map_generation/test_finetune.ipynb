{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDPMScheduler, StableDiffusionInpaintPipeline\n",
    "from osm_dataset import TextToImageDataset\n",
    "from config import CHECKPOINTS_DIR, MODEL_NAME, DEVICE, DATA_DIR\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prediction(pipe: StableDiffusionPipeline, prompt: str):\n",
    "    with torch.no_grad():\n",
    "        images = pipe(prompt, height=256, width=256).images\n",
    "\n",
    "    return images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f11cd04f4b44c9ac6d24bcbb7af76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/marcin/.cache/huggingface/datasets/imagefolder/Wrocław, PL-16adbde1af182d57/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30093710c4fa449a90cbc0060a18f50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marcin/.cache/huggingface/datasets/imagefolder/Wrocław, PL-16adbde1af182d57/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-794788cf658f2c34.arrow\n",
      "The config attributes {'predict_epsilon': True} were passed to DDPMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcin/Documents/mgr/semestr_II/nlp/nlp_l2/nlp_venv/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "/home/marcin/Documents/mgr/semestr_II/nlp/nlp_l2/nlp_venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /home/marcin/Documents/mgr/projekt_n_w/own/models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type                 | Params\n",
      "------------------------------------------------------\n",
      "0 | text_encoder | CLIPTextModel        | 123 M \n",
      "1 | vae          | AutoencoderKL        | 83.7 M\n",
      "2 | unet         | UNet2DConditionModel | 579 M \n",
      "------------------------------------------------------\n",
      "579 M     Trainable params\n",
      "206 M     Non-trainable params\n",
      "786 M     Total params\n",
      "3,144.397 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174992a17a4b4ef982d1dd0fdcf957c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcin/Documents/mgr/semestr_II/nlp/nlp_l2/nlp_venv/lib/python3.10/site-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "Epoch 0, global step 2144: 'train/loss' reached 0.12045 (best 0.12045), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 1, global step 4288: 'train/loss' reached 0.11832 (best 0.11832), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 2, global step 6432: 'train/loss' was not in top 1\n",
      "Epoch 3, global step 8576: 'train/loss' was not in top 1\n",
      "Epoch 4, global step 10720: 'train/loss' was not in top 1\n",
      "Epoch 5, global step 12864: 'train/loss' was not in top 1\n",
      "Epoch 6, global step 15008: 'train/loss' was not in top 1\n",
      "Epoch 7, global step 17152: 'train/loss' was not in top 1\n",
      "Epoch 8, global step 19296: 'train/loss' was not in top 1\n",
      "Epoch 9, global step 21440: 'train/loss' reached 0.11751 (best 0.11751), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 10, global step 23584: 'train/loss' was not in top 1\n",
      "Epoch 11, global step 25728: 'train/loss' was not in top 1\n",
      "Epoch 12, global step 27872: 'train/loss' was not in top 1\n",
      "Epoch 13, global step 30016: 'train/loss' reached 0.11736 (best 0.11736), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 14, global step 32160: 'train/loss' was not in top 1\n",
      "Epoch 15, global step 34304: 'train/loss' reached 0.11620 (best 0.11620), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 16, global step 36448: 'train/loss' was not in top 1\n",
      "Epoch 17, global step 38592: 'train/loss' was not in top 1\n",
      "Epoch 18, global step 40736: 'train/loss' was not in top 1\n",
      "Epoch 19, global step 42880: 'train/loss' was not in top 1\n",
      "Epoch 20, global step 45024: 'train/loss' was not in top 1\n",
      "Epoch 21, global step 47168: 'train/loss' was not in top 1\n",
      "Epoch 22, global step 49312: 'train/loss' was not in top 1\n",
      "Epoch 23, global step 51456: 'train/loss' was not in top 1\n",
      "Epoch 24, global step 53600: 'train/loss' reached 0.11542 (best 0.11542), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 25, global step 55744: 'train/loss' reached 0.11405 (best 0.11405), saving model to '/home/marcin/Documents/mgr/projekt_n_w/own/models/stable_wroclaw_test-v1.ckpt' as top 1\n",
      "Epoch 26, global step 57888: 'train/loss' was not in top 1\n",
      "Epoch 27, global step 60032: 'train/loss' was not in top 1\n",
      "Epoch 28, global step 62176: 'train/loss' was not in top 1\n",
      "Epoch 29, global step 64320: 'train/loss' was not in top 1\n",
      "Epoch 30, global step 66464: 'train/loss' was not in top 1\n",
      "Epoch 31, global step 68608: 'train/loss' was not in top 1\n",
      "Epoch 32, global step 70752: 'train/loss' was not in top 1\n",
      "Epoch 33, global step 72896: 'train/loss' was not in top 1\n",
      "Epoch 34, global step 75040: 'train/loss' was not in top 1\n",
      "Epoch 35, global step 77184: 'train/loss' was not in top 1\n",
      "Epoch 36, global step 79328: 'train/loss' was not in top 1\n",
      "Epoch 37, global step 81472: 'train/loss' was not in top 1\n",
      "Epoch 38, global step 83616: 'train/loss' was not in top 1\n",
      "Epoch 39, global step 85760: 'train/loss' was not in top 1\n",
      "Epoch 40, global step 87904: 'train/loss' was not in top 1\n",
      "Epoch 41, global step 90048: 'train/loss' was not in top 1\n",
      "Epoch 42, global step 92192: 'train/loss' was not in top 1\n",
      "Epoch 43, global step 94336: 'train/loss' was not in top 1\n",
      "Epoch 44, global step 96480: 'train/loss' was not in top 1\n",
      "Epoch 45, global step 98624: 'train/loss' was not in top 1\n",
      "Epoch 46, global step 100768: 'train/loss' was not in top 1\n",
      "Epoch 47, global step 102912: 'train/loss' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "# !python diff_hugging.py\n",
    "import diff_hugging\n",
    "diff_hugging.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcin/Documents/mgr/semestr_II/nlp/nlp_l2/nlp_venv/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "The config attributes {'dropout': 0.0} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "noise_scheduler = DDPMScheduler.from_pretrained(\n",
    "        \"models/wroclaw_v2\", subfolder=\"scheduler\"\n",
    "    )\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"models/wroclaw_v2\", safety_checker=None, scheduler=noise_scheduler).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f219ea19db284eccb298505306d52e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/marcin/.cache/huggingface/datasets/imagefolder/Wrocław, PL-16adbde1af182d57/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce0e390c68b42b89c6c5c082bcd0b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4367a99be304a87987d20ed56ece06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = TextToImageDataset(DATA_DIR)\n",
    "dl = DataLoader(ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate(dl, pipeline):\n",
    "    total_loss = 0.0\n",
    "    for img, caption in tqdm(dl):\n",
    "        latents = pipeline.vae.encode(\n",
    "                        img.to(DEVICE)\n",
    "                    ).latent_dist.sample()\n",
    "        latents = latents * pipeline.vae.config.scaling_factor\n",
    "\n",
    "        # Sample noise that we'll add to the latents\n",
    "        noise = torch.randn_like(latents)\n",
    "\n",
    "        bsz = latents.shape[0]\n",
    "        # Sample a random timestep for each image\n",
    "        timesteps = torch.randint(\n",
    "            0,\n",
    "            noise_scheduler.config.num_train_timesteps,\n",
    "            (bsz,),\n",
    "            device=latents.device,\n",
    "        )\n",
    "        timesteps = timesteps.long()\n",
    "\n",
    "        # Add noise to the latents according to the noise magnitude at each timestep\n",
    "        # (this is the forward diffusion process)\n",
    "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "        # Get the text embedding for conditioning\n",
    "        encoder_hidden_states = pipeline.text_encoder(caption.to(DEVICE))[0]\n",
    "\n",
    "        # Get the target for loss depending on the prediction type\n",
    "        if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "            target = noise\n",
    "        elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "            target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown prediction type {noise_scheduler.config.prediction_type}\"\n",
    "            )\n",
    "\n",
    "        # Predict the noise residual and compute loss\n",
    "        model_pred = pipeline.unet(\n",
    "            noisy_latents, timesteps, encoder_hidden_states\n",
    "        ).sample\n",
    "\n",
    "        \n",
    "        loss = F.mse_loss(\n",
    "            model_pred.float(), target.float(), reduction=\"mean\"\n",
    "            )\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2144/2144 [03:25<00:00, 10.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12338643512209016"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(dl, pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "685727852e42551632e0fc1e43e361d886b7ddaddaf1474b2acdf6903161a758"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
